---
toc: true
title:  "TeaCache を使って FramePack の生成速度向上"
date:   2025-05-19 09:00:00 +0900
categories: プログラム
tags:
- python
- 機械学習
- ComfyUI
- FramePack
- TeaCache
---
[前回][framepack] の記事で、2 秒の動画を生成するのに 7000 秒かかると書きました。さすがにこれだけ待たされると、何度も試すことが難しいですし、より長い動画を生成する気になりにくいです。

また、同じ記事の中で「6.FramePackSampler」の項目を説明した際に、以下の画像がありました。

![sampler][img08]

その中で、「use_teacache」が初期値は `true` だったのを `false` に変更していた点を忘れていました。これは、うまく生成できなくて試していた時に、「use_teacache」が `true` だとエラーになったので、RTX2070 だと対応していないのかと考えて `false` に変更しました。`false` にするとエラーが消えたので、そのままにしていたのですが、改めて確認すると、TeaCache が RTX2070 に対応しないということもなさそうです。

# TeaCache を使ってみる
![teacache][img01]

「use_teacache」を `true` に変更すれば、TeaCache を使用することになります。他は何も変更していませんが、

![teacache enabled][img02]

3100 秒ほどで生成できました。とはいえ、2 秒生成するのに 50 分以上かかっている計算なので、もうちょっと何とかしたいところです。1 秒 15 分くらい・・・は RTX2070 だと難しいですかねぇ

# TeaCache って？
モデルの出力の時間的な変化を予測し、不要な計算をスキップすることで処理速度を向上させるようです。画質に影響ないように処理を間引いている感じですかね。今のところ 2 秒程の動画しか生成しないので、画質の劣化もほとんど感じません。


[framepack]:{% post_url 2025/2025-05-13-framepack %}

[img08]:/assets/images/2025/05/ss-20250513-08.png

[img01]:/assets/images/2025/05/ss-20250517-01.png
[img02]:/assets/images/2025/05/ss-20250517-02.png
